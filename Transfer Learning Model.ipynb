{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets build an actual image recognition model using transfer learning in Keras.\n",
    "\n",
    "The model that we’ll be using here is the MobileNet.\n",
    "\n",
    "Mobile net is a model which gives reasonably good imagenet classification accuracy and occupies very less space. (17 MB according to keras docs).\n",
    "\n",
    "Dependencies Required :\n",
    "\n",
    "1. Keras (with tensorflow backend)\n",
    "2. Numpy\n",
    "3. Matplotlib\n",
    "4. Pandas\n",
    "\n",
    "Data Requirement:\n",
    "\n",
    "* The training data must be stored in a particular format in order to be fed into the network to train. We will be using ImageDataGenerator, available in keras to train our model on the available data. That way the process becomes much simpler in terms of code.\n",
    "\n",
    "* There must be a main data folder, inside that data folder, there must be a folder for each class of data containing the corresponding images. The names of the folders must be the names of their respective classes.\n",
    "\n",
    "The building of a model is a 3 step process:\n",
    "\n",
    "1. Importing the pre-trained model and adding the dense layers.\n",
    "2. Loading train data into ImageDataGenerators.\n",
    "3. Training and Evaluating model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First load the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our model -\n",
    "Then import the pre-trained MobileNet model.\n",
    "* The Mobilenet (trained on the imagenet dataset for a thousand classes) will have a last layer consisting of 1000 neurons (one for each class). We want as many neurons in the last layer of the network as the number of classes we wish to identify. So we discard the 1000 neuron layer and add our own last layer for the network.\n",
    "\n",
    "This can be done by setting (IncludeTop=False) when importing the model\n",
    "\n",
    "* We import the MobileNet model without its last layer and add a few dense layers so that our model can learn more complex functions. The dense layers must have the relu activation function and the last layer,which contains as many neurons as the number of classes must have the softmax activation.\n",
    "\n",
    "So suppose you want to train a dog breed classifier to identify 120 different breeds, we need 120 neurons in the final layer. This can be done using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyansh/.local/lib/python3.6/site-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(120,activation='softmax')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Model Architecture -\n",
    "Next we make a model based on the architecture we have provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "#specify the inputs\n",
    "#specify the outputs\n",
    "#now a model has been created based on our architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the architecture of our model, we simply need to use this line of code given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 conv_dw_1\n",
      "6 conv_dw_1_bn\n",
      "7 conv_dw_1_relu\n",
      "8 conv_pw_1\n",
      "9 conv_pw_1_bn\n",
      "10 conv_pw_1_relu\n",
      "11 conv_pad_2\n",
      "12 conv_dw_2\n",
      "13 conv_dw_2_bn\n",
      "14 conv_dw_2_relu\n",
      "15 conv_pw_2\n",
      "16 conv_pw_2_bn\n",
      "17 conv_pw_2_relu\n",
      "18 conv_dw_3\n",
      "19 conv_dw_3_bn\n",
      "20 conv_dw_3_relu\n",
      "21 conv_pw_3\n",
      "22 conv_pw_3_bn\n",
      "23 conv_pw_3_relu\n",
      "24 conv_pad_4\n",
      "25 conv_dw_4\n",
      "26 conv_dw_4_bn\n",
      "27 conv_dw_4_relu\n",
      "28 conv_pw_4\n",
      "29 conv_pw_4_bn\n",
      "30 conv_pw_4_relu\n",
      "31 conv_dw_5\n",
      "32 conv_dw_5_bn\n",
      "33 conv_dw_5_relu\n",
      "34 conv_pw_5\n",
      "35 conv_pw_5_bn\n",
      "36 conv_pw_5_relu\n",
      "37 conv_pad_6\n",
      "38 conv_dw_6\n",
      "39 conv_dw_6_bn\n",
      "40 conv_dw_6_relu\n",
      "41 conv_pw_6\n",
      "42 conv_pw_6_bn\n",
      "43 conv_pw_6_relu\n",
      "44 conv_dw_7\n",
      "45 conv_dw_7_bn\n",
      "46 conv_dw_7_relu\n",
      "47 conv_pw_7\n",
      "48 conv_pw_7_bn\n",
      "49 conv_pw_7_relu\n",
      "50 conv_dw_8\n",
      "51 conv_dw_8_bn\n",
      "52 conv_dw_8_relu\n",
      "53 conv_pw_8\n",
      "54 conv_pw_8_bn\n",
      "55 conv_pw_8_relu\n",
      "56 conv_dw_9\n",
      "57 conv_dw_9_bn\n",
      "58 conv_dw_9_relu\n",
      "59 conv_pw_9\n",
      "60 conv_pw_9_bn\n",
      "61 conv_pw_9_relu\n",
      "62 conv_dw_10\n",
      "63 conv_dw_10_bn\n",
      "64 conv_dw_10_relu\n",
      "65 conv_pw_10\n",
      "66 conv_pw_10_bn\n",
      "67 conv_pw_10_relu\n",
      "68 conv_dw_11\n",
      "69 conv_dw_11_bn\n",
      "70 conv_dw_11_relu\n",
      "71 conv_pw_11\n",
      "72 conv_pw_11_bn\n",
      "73 conv_pw_11_relu\n",
      "74 conv_pad_12\n",
      "75 conv_dw_12\n",
      "76 conv_dw_12_bn\n",
      "77 conv_dw_12_relu\n",
      "78 conv_pw_12\n",
      "79 conv_pw_12_bn\n",
      "80 conv_pw_12_relu\n",
      "81 conv_dw_13\n",
      "82 conv_dw_13_bn\n",
      "83 conv_dw_13_relu\n",
      "84 conv_pw_13\n",
      "85 conv_pw_13_bn\n",
      "86 conv_pw_13_relu\n",
      "87 global_average_pooling2d_2\n",
      "88 dense_5\n",
      "89 dense_6\n",
      "90 dense_7\n",
      "91 dense_8\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model, as we will be using the pre-trained weights, that our model has been trained on (imagenet dataset), we have to set all the weights to be non-trainable. We will only be training the last Dense layers that we have made previously. The code for doing this is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training data into the ImageDataGenerator -\n",
    "\n",
    "**ImageDataGenerators** are inbuilt in keras and help us to train our model. We just have to specify the path to our training data and it automatically sends the data for training, in batches. It makes the code much simpler.\n",
    "\n",
    "For that we need our training data in a particular format as mentioned earlier in the blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(r\"./MNIST Predictions/\", # this is where you specify the path to the main data folder\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*    The **directory** must be set to the path where your ‘n’ classes of folders are present.\n",
    "*   The **target_size** is the size of your input images, every image will be resized to this size.\n",
    "*    **color_mode**: if the image is either black and white or grayscale set “grayscale” or if the image has three colour channels, set “rgb”.\n",
    "\n",
    "*    **batch_size**: No. of images to be yielded from the generator per batch.\n",
    "*   **class_mode**: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both input and the output would probably be the same image, for this case set to “input”.\n",
    "\n",
    "*    **shuffle**: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
    "*    **seed**: Random seed for applying random image augmentation and shuffling the order of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model (after compilation) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba7d5efef0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,verbose=0, steps_per_epoch=step_size_train,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we will have trained a model. The trained model can then be used to predict which class a new unseen image belongs to, by using -\n",
    "*model.predict(new_image)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
